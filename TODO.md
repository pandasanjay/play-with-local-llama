# TODO
- [x] Successfuly steup cuda and nvida driver to work with WSL and Python env setup
- [x] Env setup where I download Lama model and run it localy using `hugging face transform`
  - Q? Using transfomrs I am not getting answer, it is just autocompletes. Same think with Olama
  - Understand transforms and how I can use with Agentic AI systm.
- [X] Run the same model using `Ollaman` As well Llama3.2:1B
- [ ] Setup langchain 
- [ ] Build first ever Multimodal App
- [ ] Spend sometime understand diffrent Model and How I can us it and when.  
